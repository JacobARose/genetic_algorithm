{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "setGPU: Setting GPU to: [0]\n",
      "Initial visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Successfully set memory_growth=True and limited GPUs visible to tensorflow.\n",
      "\n",
      "Now using GPU(s):\n",
      "['/physical_device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jacob/envs/pyleaves2.3/lib/python3.7/site-packages/wandb/vendor/graphql-core-1.1/graphql/type/directives.py:55: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  assert isinstance(locations, collections.Iterable), 'Must provide locations for directive.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 25 21:22:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   21C    P8     7W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   23C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN X (Pascal)    Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 23%   23C    P8     8W / 250W |  10367MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN X (Pascal)    Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     9W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN X (Pascal)    Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 23%   23C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN X (Pascal)    Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8     7W / 250W |  10345MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN X (Pascal)    Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 23%   21C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN X (Pascal)    Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   21C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2     30717      C   /home/matt/newtorch-env/bin/python3        10357MiB |\n",
      "|    5     22761      C   ...ata/conda/minju/envs/selfsup/bin/python 10335MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# train_ds = data['train'].map(lambda x,y: (resize(x),y)).shuffle(1024).cache().batch(config.batch_size).prefetch(-1)\n",
    "def get_hardest_k_examples(test_dataset, model, k=32):\n",
    "    class_probs = model.predict(test_dataset)\n",
    "    predictions = np.argmax(class_probs, axis=1)\n",
    "    losses = tf.keras.losses.categorical_crossentropy(test_dataset.y, class_probs)\n",
    "    argsort_loss =  np.argsort(losses)\n",
    "\n",
    "    highest_k_losses = np.array(losses)[argsort_loss[-k:]]\n",
    "    hardest_k_examples = test_dataset.x[argsort_loss[-k:]]\n",
    "    true_labels = np.argmax(test_dataset.y[argsort_loss[-k:]], axis=1)\n",
    "\n",
    "    return highest_k_losses, hardest_k_examples, true_labels, predictions\n",
    "        \n",
    "def log_high_loss_examples(test_dataset, model, k=32):\n",
    "    print(f'logging k={k} hardest examples')\n",
    "    losses, hardest_k_examples, true_labels, predictions = get_hardest_k_examples(test_dataset, model, k=k)\n",
    "    wandb.log(\n",
    "        {\"high-loss-examples\":\n",
    "                            [wandb.Image(hard_example, caption = f'true:{label},\\npred:{pred}\\nloss={loss}')\n",
    "                             for hard_example, label, pred, loss in zip(hardest_k_examples, true_labels, predictions, losses)]\n",
    "        })\n",
    "\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyleaves.utils import set_tf_config\n",
    "set_tf_config(num_gpus=1)\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# wandb.login()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, ReLU, ELU, LeakyReLU, Flatten, Dense, Add, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup, CategoryEncoding\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(666)\n",
    "tf.random.set_seed(666)\n",
    "\n",
    "from typing import List, Tuple, Union\n",
    "import tensorflow_datasets as tfds\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Which GPU is being used?\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jacob/envs/pyleaves2.3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "TFDS_DATASETS = ['plant_village']\n",
    "\n",
    "class ClassLabelEncoder:\n",
    "    def __init__(self, ds_info: tfds.core.dataset_info.DatasetInfo):\n",
    "        self.info = ds_info\n",
    "        self.dataset_name = ds_info.full_name\n",
    "        self.num_samples = ds_info.splits['train'].num_examples\n",
    "        self.num_classes = ds_info.features['label'].num_classes\n",
    "        self.class_list = ds_info.features['label'].names\n",
    "        self._str2int = ds_info.features['label'].str2int\n",
    "        self._int2str = ds_info.features['label'].int2str\n",
    "        \n",
    "    def str2int(self, labels: Union[List[str],Tuple[str]]):\n",
    "        labels = _valid_eager_tensor(labels)\n",
    "        if not isinstance(labels, [list, tuple]):\n",
    "            assert isinstance(labels, str)\n",
    "            labels = [labels]\n",
    "        return [self._str2int(l) for l in labels]\n",
    "    \n",
    "    def int2str(self, labels: Union[List[int],Tuple[int]]):\n",
    "        labels = _valid_eager_tensor(labels)\n",
    "        if not isinstance(labels, [list, tuple]):\n",
    "            assert isinstance(labels, (int, np.int64))\n",
    "            labels = [labels]\n",
    "        return [self._int2str(l) for l in labels]\n",
    "    \n",
    "    def one_hot(self, label: tf.int64):\n",
    "        '''\n",
    "        One-Hot encode integer labels\n",
    "        Use tf.data.Dataset.map(lambda x,y: (x, encoder.one_hot(y))) and pass in individual labels already encoded in int64 format.\n",
    "        '''\n",
    "        return tf.one_hot(label, depth=self.num_classes)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'''Dataset Name: {self.dataset_name}\n",
    "        Num_samples: {self.num_samples}\n",
    "        Num_classes: {self.num_classes}'''\n",
    "    \n",
    "    def _valid_eager_tensor(self, tensor, strict=False):\n",
    "        '''\n",
    "        If tensor IS an EagerTensor, return tensor.numpy(). \n",
    "        if strict==True, and tensor IS NOT an EagerTensor, then raise AssertionError.\n",
    "        if strict==False, and tensor IS NOT an EagerTensor, then return tensor without modification \n",
    "        '''\n",
    "        try:\n",
    "            assert isinstance(labels, tf.python.framework.ops.EagerTensor)\n",
    "        except AssertionError:\n",
    "            if strict:\n",
    "                raise AssertionError(f'Strict EagerTensor requirement failed assertion test in ClassLabelEncoder._valid_eager_tensor method')\n",
    "        labels = labels.numpy()\n",
    "        return labels\n",
    "\n",
    "def load_plant_village_dataset(split={'train':'train'},\n",
    "                               data_dir=None,\n",
    "                               batch_size=None):\n",
    "    \n",
    "    builder = tfds.builder(dataset_name, data_dir=data_dir)\n",
    "    ds_info = builder.info\n",
    "    builder.download_and_prepare()\n",
    "\n",
    "    print(f'splits: {split}')\n",
    "    data = builder.as_dataset(split=split,\n",
    "                              shuffle_files=True,\n",
    "                              batch_size=batch_size,\n",
    "                              as_supervised=True\n",
    "                              )\n",
    "    \n",
    "    return data, builder\n",
    "\n",
    "def load_tfds_dataset(dataset_name='plant_village', \n",
    "                      split={'train':'train'},\n",
    "                      data_dir=None,\n",
    "                      batch_size=None):\n",
    "    '''\n",
    "    General interface function to properly route users to the correct function for loading their queried dataset from Tensorflow Datasets (TFDS) public data.\n",
    "    '''\n",
    "    assert dataset_name in TFDS_DATASETS\n",
    "    \n",
    "    print(f'Getting the TFDS dataset: {dataset_name}')\n",
    "    if dataset_name == 'plant_village':\n",
    "        return load_plant_village_dataset(split      =split,\n",
    "                                          data_dir   =data_dir,\n",
    "                                          batch_size =batch_size)\n",
    "    else:\n",
    "        raise Exception('Attempted to load dataset from TFDS that we have yet to build an adapter for. Consider building a minimal working prototype by using alternative datasets as a template.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List\n",
    "from tfrecord_utils.img_utils import resize_repeat\n",
    "from boltons.funcutils import partial\n",
    "# resize = resize_repeat(target_size=config.target_size, training=False)\n",
    "def get_parse_example_func(target_size, class_encoder):\n",
    "    resize = resize_repeat(target_size=target_size, training=False)\n",
    "    def _parse_example(x, y):\n",
    "        x = tf.image.convert_image_dtype(x, tf.float32)\n",
    "        x = resize(x)\n",
    "        y = class_encoder.one_hot(y)\n",
    "        return x,y\n",
    "#         y = tf.one_hot(y, depth=num_classes)\n",
    "    return _parse_example\n",
    "\n",
    "def preprocess_data(data: tf.data.Dataset, batch_size=1, target_size=None, class_encoder=None):\n",
    "    parse_example = get_parse_example_func(target_size=target_size, class_encoder=class_encoder)\n",
    "    return data.map(lambda x,y: parse_example(x, y)) \\\n",
    "                .shuffle(1024) \\\n",
    "                .batch(batch_size) \\\n",
    "                .prefetch(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_log(dataset_name='plant_village', \n",
    "#                  data_dir    = '/media/data/jacob/tensorflow_datasets'):\n",
    "# dataset_name='plant_village'\n",
    "# data_dir = '/media/data/jacob/tensorflow_datasets'\n",
    "# if True:\n",
    "#     split = {\n",
    "#              'train': 'train[0%:60%]',\n",
    "#              'val': 'train[60%:70%]',\n",
    "#              'test': 'train[70%:100%]'\n",
    "#             }\n",
    "#     with wandb.init(project=\"artifacts-example\", job_type=\"load-data\") as run:\n",
    "#     run   = wandb.init(project=\"artifacts-example\", job_type=\"load-data\")        \n",
    "#     data, builder = load_tfds_dataset(dataset_name=dataset_name,\n",
    "#                                       split=split,\n",
    "#                                       data_dir=data_dir,\n",
    "#                                       batch_size=None)\n",
    "#     data_info     = builder.info\n",
    "#     raw_data      = wandb.Artifact(\n",
    "#                                     f\"{dataset_name}-raw\", type=\"dataset\",\n",
    "                                    \n",
    "#                                     description=\"Raw {plant_village} dataset, split into train/val/test\",\n",
    "#                                     metadata={\"source\": \"keras.datasets.mnist\",\n",
    "#                                               \"sizes\": [len(dataset.x) for dataset in datasets]})\n",
    "# split = {\n",
    "#          'train': 'train[0%:60%]',\n",
    "#          'val': 'train[60%:70%]',\n",
    "#          'test': 'train[70%:100%]'\n",
    "#         }    \n",
    "# data_dir = '/media/data/jacob/tensorflow_datasets'\n",
    "# data, ds_info = load_plant_village_dataset(split=split,\n",
    "#                                          data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and tracking label encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the TFDS dataset: plant_village\n",
      "splits: {'train': 'train[0%:60%]', 'val': 'train[60%:70%]', 'test': 'train[70%:100%]'}\n",
      "Dataset Name: plant_village/1.0.2\n",
      "        Num_samples: 54303\n",
      "        Num_classes: 38\n"
     ]
    }
   ],
   "source": [
    "dataset_name='plant_village'\n",
    "data_dir = '/media/data/jacob/tensorflow_datasets'\n",
    "\n",
    "split = {\n",
    "         'train': 'train[0%:60%]',\n",
    "         'val': 'train[60%:70%]',\n",
    "         'test': 'train[70%:100%]'\n",
    "        }\n",
    "\n",
    "data, builder = load_tfds_dataset(dataset_name=dataset_name,\n",
    "                                  split=split,\n",
    "                                  data_dir=data_dir,\n",
    "                                  batch_size=None)\n",
    "data_info     = builder.info\n",
    "class_encoder = ClassLabelEncoder(data_info)\n",
    "print(class_encoder)\n",
    "vocab = class_encoder.class_list\n",
    "\n",
    "config = OmegaConf.create({'seed':237,\n",
    "                           'batch_size':16,\n",
    "                           'input_shape':(224,224,3),\n",
    "                           'output_size':38,\n",
    "                           'epochs_per_organism':3\n",
    "                          })\n",
    "\n",
    "preprocess = partial(preprocess_data,\n",
    "                     batch_size=config.batch_size,\n",
    "                     target_size=config.input_shape[:2],\n",
    "                     class_encoder=class_encoder)\n",
    "\n",
    "data['train'] = preprocess(data=data['train']) #, batch_size=config.batch_size)\n",
    "data['val'] = preprocess(data=data['val']) #, batch_size=config.batch_size)\n",
    "data['test'] = preprocess(data=data['test']) #, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(train_ds))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x[0,...])\n",
    "# x.shape\n",
    "\n",
    "# # Load the training and testing set of CIFAR10\n",
    "# (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_train = X_train/255.\n",
    "\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_test = X_test/255.\n",
    "\n",
    "# y_train = tf.reshape(tf.one_hot(y_train, 10), shape=(-1, 10))\n",
    "# y_test = tf.reshape(tf.one_hot(y_test, 10), shape=(-1, 10))\n",
    "\n",
    "# # Create TensorFlow dataset\n",
    "# BATCH_SIZE = 256\n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# train_ds = train_ds.shuffle(1024).cache().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "# test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZRopbXcoeJ6"
   },
   "source": [
    "# Organism\n",
    "An organism contains the following:\n",
    "\n",
    "1. phase - This denotes which phase does the organism belong to\n",
    "2. chromosome - A dictionary of genes (hyperparameters)\n",
    "3. model - The `tf.keras` model corresponding to the chromosome\n",
    "4. prevBestOrganism - The best organism in the previous **phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1602853523959,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "sW1FkzdgLd8i"
   },
   "outputs": [],
   "source": [
    "options_phase0 = {\n",
    "    'a_filter_size': [(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "    'a_include_BN': [True, False],\n",
    "    'a_output_channels': [8, 16, 32, 64, 128, 256, 512],\n",
    "    'activation_type': [ReLU, ELU, LeakyReLU],\n",
    "    'b_filter_size': [(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "    'b_include_BN': [True, False],\n",
    "    'b_output_channels': [8, 16, 32, 64, 128, 256, 512],\n",
    "    'include_pool': [True, False],\n",
    "    'pool_type': [MaxPool2D, AveragePooling2D],\n",
    "    'include_skip': [True, False]\n",
    "}\n",
    "\n",
    "options = {\n",
    "    'include_layer': [True, False],\n",
    "    'a_filter_size': [(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "    'a_include_BN': [True, False],\n",
    "    'a_output_channels': [8, 16, 32, 64, 128, 256, 512],\n",
    "    'b_filter_size': [(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "    'b_include_BN': [True, False],\n",
    "    'b_output_channels': [8, 16, 32, 64, 128, 256, 512],\n",
    "    'include_pool': [True, False],\n",
    "    'pool_type': [MaxPool2D, AveragePooling2D],\n",
    "    'include_skip': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1602853525873,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "7ZjXoDSApB8b"
   },
   "outputs": [],
   "source": [
    "class Organism:\n",
    "    def __init__(self,\n",
    "                 data: Dict[str,tf.data.Dataset],\n",
    "                 config=None,\n",
    "                 chromosome={},\n",
    "                 phase=0,\n",
    "                 prevBestOrganism=None):\n",
    "        '''\n",
    "        config is a . accessible dict object containing model params that will stay constant during evolution\n",
    "        chromosome is a dictionary of genes\n",
    "        phase is the phase that the individual belongs to\n",
    "        prevBestOrganism is the best organism of the previous phase\n",
    "        \n",
    "        TODO:\n",
    "        \n",
    "        1. implement to_json and from_json methods for copies\n",
    "        2. Separate out step where organism is associated with a dataset\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.train_data = data['train']\n",
    "        self.val_data = data['val']\n",
    "        self.test_data = data['test']\n",
    "        self.config = config\n",
    "        self.phase = phase\n",
    "        self.chromosome = chromosome\n",
    "        self.prevBestOrganism=prevBestOrganism\n",
    "        if phase != 0:\n",
    "            # In a later stage, the model is made by\n",
    "            # attaching new layers to the prev best model\n",
    "            self.last_model = prevBestOrganism.model\n",
    "    \n",
    "    @property\n",
    "    def config(self):\n",
    "        return self._config\n",
    "    \n",
    "    @config.setter\n",
    "    def config(self, config=None):\n",
    "        config = config or OmegaConf.create({})\n",
    "        config.input_shape = config.input_shape or (224,224,3)\n",
    "        config.output_size = config.output_size or 38\n",
    "        config.epochs_per_organism = config.epochs_per_organism or 5\n",
    "        self._config = config\n",
    "    \n",
    "    def build_model(self):\n",
    "        '''\n",
    "        This is the function to build the keras model\n",
    "        '''\n",
    "        K.clear_session()\n",
    "        inputs = Input(shape=self.config.input_shape)\n",
    "        if self.phase != 0:\n",
    "            # Slice the prev best model\n",
    "            # Use the model as a layer\n",
    "            # Attach new layer to the sliced model\n",
    "            intermediate_model = Model(inputs=self.last_model.input,\n",
    "                                       outputs=self.last_model.layers[-3].output)\n",
    "            for layer in intermediate_model.layers:\n",
    "                # To make the iteration efficient\n",
    "                layer.trainable = False\n",
    "            inter_inputs = intermediate_model(inputs)\n",
    "            x = Conv2D(filters=self.chromosome['a_output_channels'],\n",
    "                       padding='same',\n",
    "                       kernel_size=self.chromosome['a_filter_size'],\n",
    "                       use_bias=self.chromosome['a_include_BN'])(inter_inputs)\n",
    "            # This is to ensure that we do not randomly chose anothere activation\n",
    "            self.chromosome['activation_type'] = self.prevBestOrganism.chromosome['activation_type']\n",
    "        else:\n",
    "            # For PHASE 0 only\n",
    "            # input layer\n",
    "            x = Conv2D(filters=self.chromosome['a_output_channels'],\n",
    "                       padding='same',\n",
    "                       kernel_size=self.chromosome['a_filter_size'],\n",
    "                       use_bias=self.chromosome['a_include_BN'])(inputs)\n",
    "        if self.chromosome['a_include_BN']:\n",
    "            x = BatchNormalization()(x)\n",
    "        x = self.chromosome['activation_type']()(x)\n",
    "        if self.chromosome['include_pool']:\n",
    "            x = self.chromosome['pool_type'](strides=(1,1),\n",
    "                                             padding='same')(x)\n",
    "        if self.phase != 0 and self.chromosome['include_layer'] == False:\n",
    "            # Except for PHASE0, there is a choice for\n",
    "            # the number of layers that the model wants\n",
    "            if self.chromosome['include_skip']:\n",
    "                y = Conv2D(filters=self.chromosome['a_output_channels'],\n",
    "                           kernel_size=(1,1),\n",
    "                           padding='same')(inter_inputs)\n",
    "                x = Add()([y,x])\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            x = Dense(self.output_shape, activation='softmax')(x)\n",
    "        else:\n",
    "            # PHASE0 or no skip\n",
    "            # in the tail\n",
    "            x = Conv2D(filters=self.chromosome['b_output_channels'],\n",
    "                       padding='same',\n",
    "                       kernel_size=self.chromosome['b_filter_size'],\n",
    "                       use_bias=self.chromosome['b_include_BN'])(x)\n",
    "            if self.chromosome['b_include_BN']:\n",
    "                x = BatchNormalization()(x)\n",
    "            x = self.chromosome['activation_type']()(x)\n",
    "            if self.chromosome['include_skip']:\n",
    "                y = Conv2D(filters=self.chromosome['b_output_channels'],\n",
    "                           padding='same',\n",
    "                           kernel_size=(1,1))(inputs)\n",
    "                x = Add()([y,x])\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            x = Dense(self.config.output_size, activation='softmax')(x)\n",
    "        self.model = Model(inputs=[inputs], outputs=[x])\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def fitnessFunction(self,\n",
    "                        train_data,\n",
    "                        val_data,\n",
    "                        generation_number):\n",
    "        '''\n",
    "        This function is used to calculate the\n",
    "        fitness of an individual.\n",
    "        '''\n",
    "        wandb.init(entity=\"jrose\",\n",
    "                   project=f\"vlga-plant_village\",\n",
    "                   group='KAGp{}'.format(self.phase),\n",
    "                   job_type='g{}'.format(generation_number))\n",
    "        \n",
    "        self.model.fit(train_data,\n",
    "                       epochs=self.config.epochs_per_organism,\n",
    "                       callbacks=[WandbCallback()],\n",
    "                       verbose=1)\n",
    "        _, self.fitness = self.model.evaluate(val_data,\n",
    "                                              verbose=1)\n",
    "    def crossover(self,\n",
    "                  partner,\n",
    "                  generation_number):\n",
    "        '''\n",
    "        This function helps in making children from two\n",
    "        parent individuals.\n",
    "        '''\n",
    "        child_chromosome = {}\n",
    "        endpoint = np.random.randint(low=0, high=len(self.chromosome))\n",
    "        for idx, key in enumerate(self.chromosome):\n",
    "            if idx <= endpoint:\n",
    "                child_chromosome[key] = self.chromosome[key]\n",
    "            else:\n",
    "                child_chromosome[key] = partner.chromosome[key]\n",
    "        child = Organism(chromosome=child_chromosome,\n",
    "                         data=self.data,\n",
    "                         config=self.config,\n",
    "                         phase=self.phase,\n",
    "                         prevBestOrganism=self.prevBestOrganism)\n",
    "        child.build_model()\n",
    "        child.fitnessFunction(self.train_data,\n",
    "                              self.val_data,\n",
    "                              generation_number=generation_number)\n",
    "        return child\n",
    "    \n",
    "    def mutation(self, generation_number):\n",
    "        '''\n",
    "        One of the gene is to be mutated.\n",
    "        '''\n",
    "        index = np.random.randint(0, len(self.chromosome))\n",
    "        key = list(self.chromosome.keys())[index]\n",
    "        if  self.phase != 0:\n",
    "            self.chromosome[key] = options[key][np.random.randint(len(options[key]))]\n",
    "        else:\n",
    "            self.chromosome[key] = options_phase0[key][np.random.randint(len(options_phase0[key]))]\n",
    "        self.build_model()\n",
    "        self.fitnessFunction(self.train_data,\n",
    "                             self.val_data,\n",
    "                             generation_number=generation_number)\n",
    "    \n",
    "    def show(self):\n",
    "        '''\n",
    "        Util function to show the individual's properties.\n",
    "        '''\n",
    "        pp.pprint(self.config)\n",
    "        pp.pprint(self.chromosome)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1602853526635,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "0vs3EmGeiDWC"
   },
   "outputs": [],
   "source": [
    "def random_hyper(phase):\n",
    "    if phase == 0:\n",
    "        return {\n",
    "        'a_filter_size': options_phase0['a_filter_size'][np.random.randint(len(options_phase0['a_filter_size']))],\n",
    "        'a_include_BN': options_phase0['a_include_BN'][np.random.randint(len(options_phase0['a_include_BN']))],\n",
    "        'a_output_channels': options_phase0['a_output_channels'][np.random.randint(len(options_phase0['a_output_channels']))],\n",
    "        'activation_type': options_phase0['activation_type'][np.random.randint(len(options_phase0['activation_type']))],\n",
    "        'b_filter_size': options_phase0['b_filter_size'][np.random.randint(len(options_phase0['b_filter_size']))],\n",
    "        'b_include_BN': options_phase0['b_include_BN'][np.random.randint(len(options_phase0['b_include_BN']))],\n",
    "        'b_output_channels': options_phase0['b_output_channels'][np.random.randint(len(options_phase0['b_output_channels']))],\n",
    "        'include_pool': options_phase0['include_pool'][np.random.randint(len(options_phase0['include_pool']))],\n",
    "        'pool_type': options_phase0['pool_type'][np.random.randint(len(options_phase0['pool_type']))],\n",
    "        'include_skip': options_phase0['include_skip'][np.random.randint(len(options_phase0['include_skip']))]\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "        'a_filter_size': options['a_filter_size'][np.random.randint(len(options['a_filter_size']))],\n",
    "        'a_include_BN': options['a_include_BN'][np.random.randint(len(options['a_include_BN']))],\n",
    "        'a_output_channels': options['a_output_channels'][np.random.randint(len(options['a_output_channels']))],\n",
    "        'b_filter_size': options['b_filter_size'][np.random.randint(len(options['b_filter_size']))],\n",
    "        'b_include_BN': options['b_include_BN'][np.random.randint(len(options['b_include_BN']))],\n",
    "        'b_output_channels': options['b_output_channels'][np.random.randint(len(options['b_output_channels']))],\n",
    "        'include_pool': options['include_pool'][np.random.randint(len(options['include_pool']))],\n",
    "        'pool_type': options['pool_type'][np.random.randint(len(options['pool_type']))],\n",
    "        'include_layer': options['include_layer'][np.random.randint(len(options['include_layer']))],\n",
    "        'include_skip': options['include_skip'][np.random.randint(len(options['include_skip']))]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1514,
     "status": "ok",
     "timestamp": 1602853528363,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "6L1SwfFOotpO"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEVFOsxlc8ef"
   },
   "source": [
    "# Generation\n",
    "This is a class that hold generations of models.\n",
    "\n",
    "1. fitSurvivalRate - The amount of fit individuals we want in the next generation.\n",
    "2. unfitSurvivalProb - The probability of sending unfit individuals\n",
    "3. mutationRate - The mutation rate to change genes in an individual.\n",
    "4. phase - The phase that the generation belongs to.\n",
    "5. population_size - The amount of individuals that the generation consists of.\n",
    "6. prevBestOrganism - The best organism (individual) is the last phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1602853528916,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "cfa1Y5TNVYcY"
   },
   "outputs": [],
   "source": [
    "class Generation:\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 config,\n",
    "                 fitSurvivalRate,\n",
    "                 unfitSurvivalProb,\n",
    "                 mutationRate,\n",
    "                 phase,\n",
    "                 population_size,\n",
    "                 prevBestOrganism):\n",
    "        self.data = data\n",
    "        self.config = config\n",
    "#         self.population_size = population_size\n",
    "        self.population = []\n",
    "        self.generation_number = 0\n",
    "#         self.mutationRate = mutationRate\n",
    "#         self.fitSurvivalRate = fitSurvivalRate\n",
    "#         self.unfitSurvivalProb = unfitSurvivalProb\n",
    "#         self.prevBestOrganism = prevBestOrganism\n",
    "        self.phase = phase\n",
    "        # creating the first population: GENERATION_0\n",
    "        # can be thought of as the setup function\n",
    "        \n",
    "        self.initialize_population()\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        return self._config\n",
    "    \n",
    "    @config.setter\n",
    "    def config(self, config=None):\n",
    "        config = config or OmegaConf.create({})\n",
    "        config.population_size = config.population_size or 5\n",
    "        config.num_generations_per_phase = config.num_generations_per_phase or 3\n",
    "        config.fitSurvivalRate = config.fitSurvivalRate or 0.5\n",
    "        config.unfitSurvivalProb = config.unfitSurvivalProb or 0.2\n",
    "        config.mutationRate = config.mutationRate or 0.1\n",
    "        config.num_phases = config.num_phases or 5\n",
    "        \n",
    "        self._config = config\n",
    "        self.__dict__.update(config)\n",
    "        \n",
    "        \n",
    "    def initialize_population(self):\n",
    "        '''\n",
    "        1. Create self.population_size individual organisms from scratch by randomly sampling an initial set of hyperparameters (a chromosome)\n",
    "        2. As each is instantiated, build its model\n",
    "        3. Assess their fitness one-by-one\n",
    "        4. Sort models by relative fitness so we have a (potentially) new Best Organism (best model)\n",
    "        4. Increment generation number to 1\n",
    "        '''\n",
    "\n",
    "        for idx in range(self.population_size):\n",
    "            print(f'Creating, training then testing organism {idx} of generation {self.generation_number} and phase {self.phase}')\n",
    "            org = Organism(chromosome=random_hyper(self.phase),\n",
    "                           data=self.data,\n",
    "                           config=self.config,\n",
    "                           phase=self.phase,\n",
    "                           prevBestOrganism=self.prevBestOrganism)\n",
    "            org.build_model()\n",
    "            org.fitnessFunction(org.data['train'],\n",
    "                                org.data['test'],\n",
    "                                generation_number=self.generation_number)\n",
    "            self.population.append(org)\n",
    "\n",
    "        # sorts the population according to fitness (high to low)\n",
    "        self.sortModel()\n",
    "        self.generation_number += 1\n",
    "\n",
    "    def sortModel(self):\n",
    "        '''\n",
    "        sort the models according to the \n",
    "        fitness in descending order.\n",
    "        '''\n",
    "        fitness = [ind.fitness for ind in self.population]\n",
    "        sort_index = np.argsort(fitness)[::-1]\n",
    "        self.population = [self.population[index] for index in sort_index]\n",
    "\n",
    "    def generate(self):\n",
    "        '''\n",
    "        Generate a new generation in the same phase\n",
    "        '''\n",
    "        number_of_fit = int(self.population_size * self.fitSurvivalRate)\n",
    "        new_pop = self.population[:number_of_fit]\n",
    "        for individual in self.population[number_of_fit:]:\n",
    "            if np.random.rand() <= self.unfitSurvivalProb:\n",
    "                new_pop.append(individual)\n",
    "        for index, individual in enumerate(new_pop):\n",
    "            if np.random.rand() <= self.mutationRate:\n",
    "                new_pop[index].mutation(generation_number=self.generation_number)\n",
    "        fitness = [ind.fitness for ind in new_pop]\n",
    "        children=[]\n",
    "        for idx in range(self.population_size-len(new_pop)):\n",
    "            parents = np.random.choice(new_pop, replace=False, size=(2,), p=softmax(fitness))\n",
    "            A=parents[0]\n",
    "            B=parents[1]\n",
    "            child=A.crossover(B, generation_number=self.generation_number)\n",
    "            children.append(child)\n",
    "        self.population = new_pop+children\n",
    "        self.sortModel()\n",
    "        self.generation_number+=1\n",
    "\n",
    "    def evaluate(self, last=False):\n",
    "        '''\n",
    "        Evaluate the generation\n",
    "        '''\n",
    "        fitness = [ind.fitness for ind in self.population]\n",
    "        wandb.log({'Best fitness': fitness[0]})\n",
    "        wandb.log({'Average fitness': sum(fitness)/len(fitness)})\n",
    "        \n",
    "        self.population[0].show()\n",
    "        if last:\n",
    "            return self.population[0]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 37514,
     "status": "error",
     "timestamp": 1602853256806,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "3BbVfUL3nZrh",
    "outputId": "db81b47f-a3be-4b2b-88e3-f0b1db702b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 0\n",
      "Creating, training then testing organism 0 of generation 0 and phase 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjrose\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">likely-field-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/3nsr9eb6\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/3nsr9eb6</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_115829-3nsr9eb6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2037/2037 [==============================] - 469s 230ms/step - loss: 1.8262 - accuracy: 0.4844\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 469s 230ms/step - loss: 1.3346 - accuracy: 0.6083\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 469s 230ms/step - loss: 1.1709 - accuracy: 0.6547\n",
      "1019/1019 [==============================] - 96s 95ms/step - loss: 1.6317 - accuracy: 0.5230\n",
      "Creating, training then testing organism 1 of generation 0 and phase 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23956<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.42MB of 0.42MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_115829-3nsr9eb6/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_115829-3nsr9eb6/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.17093</td></tr><tr><td>accuracy</td><td>0.65469</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>1422</td></tr><tr><td>_timestamp</td><td>1606324931</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">likely-field-7</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/3nsr9eb6\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/3nsr9eb6</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">zany-surf-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/29b22i6j\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/29b22i6j</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_122351-29b22i6j</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2037/2037 [==============================] - 168s 83ms/step - loss: 2.3962 - accuracy: 0.3468\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 168s 83ms/step - loss: 1.8277 - accuracy: 0.4797\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 168s 83ms/step - loss: 1.6019 - accuracy: 0.5393\n",
      "1019/1019 [==============================] - 38s 37ms/step - loss: 2.1126 - accuracy: 0.4076\n",
      "Creating, training then testing organism 2 of generation 0 and phase 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4908<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.39MB of 0.39MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_122351-29b22i6j/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_122351-29b22i6j/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.6019</td></tr><tr><td>accuracy</td><td>0.53925</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>517</td></tr><tr><td>_timestamp</td><td>1606325551</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▄█</td></tr><tr><td>_timestamp</td><td>▁▄█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">zany-surf-8</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/29b22i6j\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/29b22i6j</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">driven-fog-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2d86v6mx\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2d86v6mx</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_123312-2d86v6mx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2037/2037 [==============================] - 366s 180ms/step - loss: 2.4685 - accuracy: 0.3378\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 365s 179ms/step - loss: 1.7953 - accuracy: 0.4989\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 365s 179ms/step - loss: 1.5355 - accuracy: 0.5580\n",
      "1019/1019 [==============================] - 64s 63ms/step - loss: 2.2061 - accuracy: 0.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating, training then testing organism 3 of generation 0 and phase 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10126<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.39MB of 0.39MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_123312-2d86v6mx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_123312-2d86v6mx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.53547</td></tr><tr><td>accuracy</td><td>0.55801</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>1108</td></tr><tr><td>_timestamp</td><td>1606326703</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">driven-fog-9</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2d86v6mx\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2d86v6mx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">laced-pond-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/1lqgmthj\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/1lqgmthj</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_125250-1lqgmthj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2/2037 [..............................] - ETA: 5:53 - loss: 3.6445 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1022s vs `on_train_batch_end` time: 0.2430s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1022s vs `on_train_batch_end` time: 0.2430s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037/2037 [==============================] - 708s 347ms/step - loss: 2.3491 - accuracy: 0.3520\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 707s 347ms/step - loss: 1.7677 - accuracy: 0.4961\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 707s 347ms/step - loss: 1.6043 - accuracy: 0.5348\n",
      "1019/1019 [==============================] - 103s 101ms/step - loss: 2.2794 - accuracy: 0.39191:03 - los - ETA: 59s - loss: 2.2894 - accuracy: 0. - ETA: 59s - loss: 2.2911 - ac - ETA: 57s - loss: 2.2826 - accuracy: 0.38 - ETA: 57s - loss: 2.2844 - accuracy: - ETA: 57s - loss: 2. - ETA: 13s - loss: 2.27 - ETA: 8s - loss: 2.277 - ETA: 5s - loss: - ETA: 3s - loss: 2.2 - ETA: 0s - loss: 2.2799 - accuracy: 0. - ETA: 0s - loss: 2.2801 - accura\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating, training then testing organism 4 of generation 0 and phase 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19953<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.40MB of 0.40MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_125250-1lqgmthj/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_125250-1lqgmthj/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.60427</td></tr><tr><td>accuracy</td><td>0.53477</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>2135</td></tr><tr><td>_timestamp</td><td>1606328909</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▇█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">laced-pond-10</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/1lqgmthj\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/1lqgmthj</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">swept-durian-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/1f2md7tj\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/1f2md7tj</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_133015-1f2md7tj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2/2037 [..............................] - ETA: 1:12 - loss: 3.7139 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0275s vs `on_train_batch_end` time: 0.0433s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0275s vs `on_train_batch_end` time: 0.0433s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037/2037 [==============================] - 131s 64ms/step - loss: 2.8168 - accuracy: 0.2565s - loss: 2.8173 - accuracy: \n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 130s 64ms/step - loss: 2.2217 - accuracy: 0.3824\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 131s 64ms/step - loss: 1.9733 - accuracy: 0.4393\n",
      "1019/1019 [==============================] - 38s 37ms/step - loss: 2.5129 - accuracy: 0.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6922<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.40MB of 0.40MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_133015-1f2md7tj/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_133015-1f2md7tj/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.97332</td></tr><tr><td>accuracy</td><td>0.43932</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>402</td></tr><tr><td>_timestamp</td><td>1606329421</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">swept-durian-11</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/1f2md7tj\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/1f2md7tj</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glorious-wave-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/3dyzh5al\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/3dyzh5al</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_133742-3dyzh5al</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2/2037 [..............................] - ETA: 3:09 - loss: 4.2281 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0679s vs `on_train_batch_end` time: 0.1169s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0679s vs `on_train_batch_end` time: 0.1169s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037/2037 [==============================] - 365s 179ms/step - loss: 2.7063 - accuracy: 0.2854\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 365s 179ms/step - loss: 1.9617 - accuracy: 0.4466\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 365s 179ms/step - loss: 1.5333 - accuracy: 0.5568\n",
      "340/340 [==============================] - 21s 62ms/step - loss: 2.5094 - accuracy: 0.3549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11146<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.41MB of 0.41MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_133742-3dyzh5al/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_133742-3dyzh5al/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.53334</td></tr><tr><td>accuracy</td><td>0.55678</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>1106</td></tr><tr><td>_timestamp</td><td>1606330573</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▄▁</td></tr><tr><td>accuracy</td><td>▁▅█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▄█</td></tr><tr><td>_timestamp</td><td>▁▄█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">glorious-wave-12</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/3dyzh5al\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/3dyzh5al</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">noble-cloud-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2cxlyva0\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2cxlyva0</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_135637-2cxlyva0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2/2037 [..............................] - ETA: 3:09 - loss: 4.1003 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0718s vs `on_train_batch_end` time: 0.1154s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0718s vs `on_train_batch_end` time: 0.1154s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037/2037 [==============================] - 380s 187ms/step - loss: 2.6983 - accuracy: 0.2866\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 380s 187ms/step - loss: 2.1444 - accuracy: 0.3999\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 380s 187ms/step - loss: 1.7825 - accuracy: 0.4845\n",
      "340/340 [==============================] - 24s 70ms/step - loss: 2.1458 - accuracy: 0.4236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20752<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.42MB of 0.42MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_135637-2cxlyva0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_135637-2cxlyva0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.78251</td></tr><tr><td>accuracy</td><td>0.48453</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>1151</td></tr><tr><td>_timestamp</td><td>1606331752</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▄▁</td></tr><tr><td>accuracy</td><td>▁▅█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">noble-cloud-13</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2cxlyva0\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2cxlyva0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">young-sun-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2fdjde8q\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2fdjde8q</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_141619-2fdjde8q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2037/2037 [==============================] - 471s 231ms/step - loss: 1.8428 - accuracy: 0.4838\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 472s 232ms/step - loss: 1.3477 - accuracy: 0.6079\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 473s 232ms/step - loss: 1.1813 - accuracy: 0.6518\n",
      "340/340 [==============================] - 32s 94ms/step - loss: 2.8690 - accuracy: 0.3339\n",
      "{'seed': 237, 'batch_size': 16, 'input_shape': [224, 224, 3], 'output_size': 38, 'epochs_per_organism': 3}\n",
      "{   'a_filter_size': (9, 9),\n",
      "    'a_include_BN': True,\n",
      "    'a_output_channels': 256,\n",
      "    'activation_type': <class 'tensorflow.python.keras.layers.advanced_activations.LeakyReLU'>,\n",
      "    'b_filter_size': (3, 3),\n",
      "    'b_include_BN': True,\n",
      "    'b_output_channels': 128,\n",
      "    'include_pool': False,\n",
      "    'include_skip': True,\n",
      "    'pool_type': <class 'tensorflow.python.keras.layers.pooling.AveragePooling2D'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31013<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.42MB of 0.42MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_141619-2fdjde8q/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_141619-2fdjde8q/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.18128</td></tr><tr><td>accuracy</td><td>0.6518</td></tr><tr><td>_step</td><td>4</td></tr><tr><td>_runtime</td><td>1462</td></tr><tr><td>_timestamp</td><td>1606333245</td></tr><tr><td>Best fitness</td><td>0.52305</td></tr><tr><td>Average fitness</td><td>0.41186</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>_step</td><td>▁▃▅▆█</td></tr><tr><td>_runtime</td><td>▁▄███</td></tr><tr><td>_timestamp</td><td>▁▄███</td></tr><tr><td>Best fitness</td><td>▁</td></tr><tr><td>Average fitness</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">young-sun-14</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2fdjde8q\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2fdjde8q</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">pretty-fire-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2i85x7t1\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2i85x7t1</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_144045-2i85x7t1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2/2037 [..............................] - ETA: 12:38 - loss: 6.0652 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1219s vs `on_train_batch_end` time: 0.6232s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1219s vs `on_train_batch_end` time: 0.6232s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037/2037 [==============================] - 1517s 745ms/step - loss: 2.0466 - accuracy: 0.4767\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 1506s 739ms/step - loss: 1.0902 - accuracy: 0.6771\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 1500s 736ms/step - loss: 0.8010 - accuracy: 0.7587\n",
      "340/340 [==============================] - 38s 111ms/step - loss: 1.0996 - accuracy: 0.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11526<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.43MB of 0.43MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201125_144045-2i85x7t1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201125_144045-2i85x7t1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.80103</td></tr><tr><td>accuracy</td><td>0.7587</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>_runtime</td><td>4540</td></tr><tr><td>_timestamp</td><td>1606337788</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>_step</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">pretty-fire-15</strong>: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/2i85x7t1\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/2i85x7t1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">true-wildflower-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/vlga-plant_village\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/vlga-plant_village/runs/d65lbldi\" target=\"_blank\">https://wandb.ai/jrose/vlga-plant_village/runs/d65lbldi</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201125_155709-d65lbldi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   2/2037 [..............................] - ETA: 3:08 - loss: 3.9250 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0666s vs `on_train_batch_end` time: 0.1163s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0666s vs `on_train_batch_end` time: 0.1163s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037/2037 [==============================] - 364s 179ms/step - loss: 2.5563 - accuracy: 0.3154\n",
      "Epoch 2/3\n",
      "2037/2037 [==============================] - 364s 179ms/step - loss: 2.0210 - accuracy: 0.4357\n",
      "Epoch 3/3\n",
      "2037/2037 [==============================] - 364s 179ms/step - loss: 1.7580 - accuracy: 0.5004\n",
      "340/340 [==============================] - 21s 63ms/step - loss: 2.6488 - accuracy: 0.3076\n",
      "{'seed': 237, 'batch_size': 16, 'input_shape': [224, 224, 3], 'output_size': 38, 'epochs_per_organism': 3}\n",
      "{   'a_filter_size': (5, 5),\n",
      "    'a_include_BN': True,\n",
      "    'a_output_channels': 256,\n",
      "    'activation_type': <class 'tensorflow.python.keras.layers.advanced_activations.ELU'>,\n",
      "    'b_filter_size': (9, 9),\n",
      "    'b_include_BN': False,\n",
      "    'b_output_channels': 128,\n",
      "    'include_pool': False,\n",
      "    'include_skip': True,\n",
      "    'pool_type': <class 'tensorflow.python.keras.layers.pooling.AveragePooling2D'>}\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-227f0b51480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprevBestOrganism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevBestOrganism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"best_model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Best Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             log_high_loss_examples(prevBestOrganism.test_dataset,\n\u001b[1;32m     28\u001b[0m                                    \u001b[0mprevBestOrganism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/jacob/envs/pyleaves2.3/lib/python3.7/site-packages/wandb/data_types.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_or_path, mode, caption, grouping, boxes, masks)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/jacob/envs/pyleaves2.3/lib/python3.7/site-packages/wandb/data_types.py\u001b[0m in \u001b[0;36m_set_file\u001b[0;34m(self, path, is_tmp, extension)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Media file extension \"{}\" must occur at the end of path \"{}\".'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sha256\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best.png'"
     ]
    }
   ],
   "source": [
    "# population_size = 5\n",
    "# num_generations_per_phase = 3\n",
    "# fitSurvivalRate = 0.5\n",
    "# unfitSurvivalProb = 0.2\n",
    "# mutationRate = 0.1\n",
    "# num_phases = 5\n",
    "# prevBestOrganism = None\n",
    "\n",
    "generation_config = OmegaConf.create({\n",
    "                                      'population_size':5,\n",
    "                                      'num_generations_per_phase':3,\n",
    "                                      'fitSurvivalRate': 0.5,\n",
    "                                      'unfitSurvivalProb':0.2,\n",
    "                                      'mutationRate':0.1,\n",
    "                                      'num_phases':5\n",
    "                                    })\n",
    "prevBestOrganism = None\n",
    "\n",
    "\n",
    "\n",
    "for phase in range(num_phases):\n",
    "    print(\"PHASE {}\".format(phase))\n",
    "    generation = Generation(data=data,\n",
    "                            config=config,\n",
    "                            fitSurvivalRate=fitSurvivalRate,\n",
    "                            unfitSurvivalProb=unfitSurvivalProb,\n",
    "                            mutationRate=mutationRate,\n",
    "                            population_size=population_size,\n",
    "                            phase=phase,\n",
    "                            prevBestOrganism=prevBestOrganism)\n",
    "#     while generation.generation_number < num_generations_per_phase:\n",
    "    generation.generate()\n",
    "    if generation.generation_number == num_generations_per_phase:\n",
    "        # Last generation is the phase\n",
    "        # print('I AM THE BEST IN THE PHASE')\n",
    "        prevBestOrganism = generation.evaluate(last=True)\n",
    "        model_path = f'best-model-phase_{phase}.png'\n",
    "        tf.keras.utils.plot_model(prevBestOrganism.model, to_file=model_path)\n",
    "        wandb.log({\"best_model\": [wandb.Image(model_path, caption=f\"Best Model phase_{phase}\")]})\n",
    "        log_high_loss_examples(prevBestOrganism.test_dataset,\n",
    "                               prevBestOrganism.model, \n",
    "                               k=32)\n",
    "    else:\n",
    "        generation.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Using tfds.features.ClassLabel\n",
    "\n",
    "# feature_labels = tfds.features.ClassLabel(names=vocab)\n",
    "# data = ['Potato___healthy',\n",
    "#         'Potato___Late_blight',\n",
    "#         'Raspberry___healthy',\n",
    "#         'Soybean___healthy',\n",
    "#         'Squash___Powdery_mildew',\n",
    "#         'Strawberry___healthy',\n",
    "#         'Strawberry___Leaf_scorch',\n",
    "#         'Tomato___Bacterial_spot',\n",
    "#         'Tomato___Early_blight',\n",
    "#         'Tomato___healthy']\n",
    "\n",
    "# data += data[::-1]\n",
    "# print([feature_labels.str2int(label) for label in data])\n",
    "# data = train_data\n",
    "# data_enc = data.map(lambda x,y: (x, feature_labels.int2str(y)))\n",
    "\n",
    "### 2. Using StringLookup and CategoryEncoding Layers\n",
    "\n",
    "# layer = StringLookup(vocabulary=vocab, num_oov_indices=0, mask_token=None)\n",
    "# i_layer = StringLookup(vocabulary=layer.get_vocabulary(), invert=True)\n",
    "# int_data = layer(data)\n",
    "\n",
    "# print(len(layer.get_vocabulary()))\n",
    "# print(len(class_encoder.class_list))\n",
    "# print(set(layer.get_vocabulary())==set(class_encoder.class_list))\n",
    "\n",
    "# i_layer = StringLookup(vocabulary=layer.get_vocabulary(), invert=True)\n",
    "# int_data = layer(data)\n",
    "\n",
    "# print(layer(data))\n",
    "# print(i_layer(int_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from tensorflow.keras.layers.experimental.preprocessing import StringLookup, CategoryEncoding\n",
    "# # data = tf.constant([\"a\", \"b\", \"c\", \"b\", \"c\", \"a\"])\n",
    "# # # Use StringLookup to build an index of the feature values\n",
    "# # indexer = StringLookup()\n",
    "# # indexer.adapt(data)\n",
    "# # # Use CategoryEncoding to encode the integer indices to a one-hot vector\n",
    "# # encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "# # encoder.adapt(indexer(data))\n",
    "# # # Convert new test data (which includes unknown feature values)\n",
    "# # test_data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"e\", \"\"])\n",
    "# # encoded_data = encoder(indexer(test_data))\n",
    "# # print(encoded_data)\n",
    "\n",
    "# vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
    "# data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
    "# layer = StringLookup(vocabulary=vocab)\n",
    "# i_layer = StringLookup(vocabulary=layer.get_vocabulary(), invert=True)\n",
    "# int_data = layer(data)\n",
    "\n",
    "# print(layer(data))\n",
    "# print(i_layer(int_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
