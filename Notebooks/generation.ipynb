{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG =False #True # #  False #\n",
    "\n",
    "import os\n",
    "# if not DEBUG:\n",
    "#     os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyleaves.utils import set_tf_config\n",
    "set_tf_config(num_gpus=1)\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# wandb.login()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, ReLU, ELU, LeakyReLU, Flatten, Dense, Add, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup, CategoryEncoding\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "##\n",
    "# Always randomly set the seed + log value for future replication for experiments by default,\n",
    "# but if DEBUG is set to True, then seed all random generators with a hard coded value\n",
    "##\n",
    "import random\n",
    "nb_seed = random.randint(0,1e5)\n",
    "if DEBUG:\n",
    "    nb_seed = 374  \n",
    "np.random.seed(nb_seed)\n",
    "tf.random.set_seed(nb_seed)\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('science')\n",
    "from typing import List, Tuple, Union, Dict, NamedTuple\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# from tfrecord_utils.img_utils import resize_repeat\n",
    "# from boltons.funcutils import partial\n",
    "# import logging\n",
    "# logger = logging.getLogger('')\n",
    "\n",
    "LOG_DIR = '/media/data/jacob/GitHub/experiment_results/evolution_logs'\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "from paleoai_data.utils.logging_utils import get_logger\n",
    "logger = get_logger(logdir=LOG_DIR, filename='generation_evolution_logs.log', append=True)\n",
    "\n",
    "VERBOSE = True\n",
    "import pandas as pd\n",
    "import json\n",
    "import jsonpickle\n",
    "from box import Box\n",
    "from bunch import Bunch\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from genetic_algorithm.datasets.plant_village import ClassLabelEncoder, load_and_preprocess_data\n",
    "from genetic_algorithm import stateful\n",
    "\n",
    "from genetic_algorithm.chromosome import ChromosomeSampler\n",
    "from genetic_algorithm.organism.organism import Organism\n",
    "from genetic_algorithm.generation.generation import Generation\n",
    "from genetic_algorithm.plotting import log_high_loss_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = OmegaConf.create({'seed':756, #237,\n",
    "                               'batch_size':8,#16,\n",
    "                               'input_shape':(224,224,3),\n",
    "                               'output_size':38,\n",
    "                               'epochs_per_organism':3,\n",
    "                               'results_dir':'/media/data_cifs_lrs/projects/prj_fossils/users/jacob/experiments/Nov2020-Jan2021',\n",
    "                               'experiment_uid':str(np.random.randint(0,1e10))\n",
    "                              })\n",
    "exp_config.model_dir = os.path.join(exp_config.results_dir,exp_config.experiment_uid)\n",
    "\n",
    "data_config = OmegaConf.create({'load':{},'preprocess':{}})\n",
    "\n",
    "data_config['load'] = {'dataset_name':'plant_village',\n",
    "                       'split':['train[0%:60%]','train[60%:70%]','train[70%:100%]'],\n",
    "                       'data_dir':'/media/data/jacob/tensorflow_datasets'}\n",
    "\n",
    "data_config['preprocess'] = {'batch_size':exp_config.batch_size,\n",
    "                             'target_size':exp_config.input_shape[:2]}\n",
    "\n",
    "generation_config = OmegaConf.create({\n",
    "                                      'population_size':5,\n",
    "                                      'num_generations_per_phase':3,\n",
    "                                      'fitSurvivalRate': 0.5,\n",
    "                                      'unfitSurvivalProb':0.2,\n",
    "                                      'mutationRate':0.1,\n",
    "                                      'num_phases':5\n",
    "                                    })\n",
    "organism_config = OmegaConf.create({'input_shape':exp_config.input_shape,\n",
    "                                    'output_size':exp_config.output_size,\n",
    "                                    'epochs_per_organism':exp_config.epochs_per_organism,\n",
    "                                    'model_dir':exp_config.model_dir,\n",
    "                                    'experiment_uid':exp_config.experiment_uid})\n",
    "\n",
    "if DEBUG:\n",
    "    exp_config = OmegaConf.create({'seed':6227,\n",
    "                                   'batch_size':16,\n",
    "                                   'input_shape':(64,64,3),\n",
    "                                   'output_size':38,\n",
    "                                   'epochs_per_organism':1,\n",
    "                                   'results_dir':'/media/data_cifs_lrs/projects/prj_fossils/users/jacob/experiments/Nov2020-Jan2021/debugging_trials',\n",
    "                                   'experiment_uid':str(np.random.randint(0,1e10))\n",
    "                                  })\n",
    "    exp_config.model_dir = os.path.join(exp_config.results_dir,exp_config.experiment_uid)\n",
    "\n",
    "    data_config = OmegaConf.create({'load':{},'preprocess':{}})\n",
    "    data_config['load'] = {'dataset_name':'plant_village',\n",
    "                           'split':['train[0%:60%]','train[60%:70%]','train[70%:100%]'],\n",
    "                           'data_dir':'/media/data/jacob/tensorflow_datasets'}\n",
    "\n",
    "    data_config['preprocess'] = {'batch_size':exp_config.batch_size,\n",
    "                                 'target_size':exp_config.input_shape[:2]}\n",
    "\n",
    "    generation_config = OmegaConf.create({\n",
    "                                          'population_size':3,\n",
    "                                          'num_generations_per_phase':2,\n",
    "                                          'fitSurvivalRate': 0.5,\n",
    "                                          'unfitSurvivalProb':0.2,\n",
    "                                          'mutationRate':0.1,\n",
    "                                          'num_phases':3\n",
    "                                        })\n",
    "    organism_config = OmegaConf.create({'input_shape':exp_config.input_shape,\n",
    "                                        'output_size':exp_config.output_size,\n",
    "                                        'epochs_per_organism':exp_config.epochs_per_organism,\n",
    "                                        'model_dir':exp_config.model_dir,\n",
    "                                        'experiment_uid':exp_config.experiment_uid})\n",
    "\n",
    "config = OmegaConf.create({\n",
    "                            'experiment':exp_config,\n",
    "                            'data':data_config,\n",
    "                            'generation':generation_config,\n",
    "                            'organism':organism_config\n",
    "})\n",
    "print(config.pretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data, and acquire the class_encoder\n",
    "#### Finally, alter config values based on whether running in DEBUG mode or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, class_encoder = load_and_preprocess_data(config['data'])\n",
    "if DEBUG:\n",
    "    config.organism.steps_per_epoch = 150\n",
    "    config.organism.validation_steps = 150\n",
    "else:\n",
    "    config.organism.steps_per_epoch = len(data['train'])\n",
    "    config.organism.validation_steps = len(data['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZRopbXcoeJ6"
   },
   "source": [
    "# Organism\n",
    "An organism contains the following:\n",
    "\n",
    "1. phase - This denotes which phase does the organism belong to\n",
    "2. chromosome - A dictionary of genes (hyperparameters)\n",
    "3. model - The `tf.keras` model corresponding to the chromosome\n",
    "4. best_organism - The best organism in the previous **phase**\n",
    "\n",
    "# Generation\n",
    "This is a class that hold generations of models.\n",
    "\n",
    "1. fitSurvivalRate - The amount of fit individuals we want in the next generation.\n",
    "2. unfitSurvivalProb - The probability of sending unfit individuals\n",
    "3. mutationRate - The mutation rate to change genes in an individual.\n",
    "4. phase - The phase that the generation belongs to.\n",
    "5. population_size - The amount of individuals that the generation consists of.\n",
    "6. best_organism - The best organism (individual) is the last phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'generation_main.ipynb'\n",
    "%reload_ext memory_profiler\n",
    "%cd /media/data/jacob/GitHub/genetic_algorithm\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "from main import main\n",
    "best_organism, last_generation = main(data=data, config=config, best_organism = None, class_encoder=class_encoder, verbose=True, debug=DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_generation.population\n",
    "\n",
    "from genetic_algorithm.plotting import *\n",
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "run = wandb.init(entity='jrose')\n",
    "\n",
    "# log_multiclass_metrics(best_organism.test_data, \n",
    "#                        best_organism.model,\n",
    "#                        data_split_name='test', \n",
    "#                        class_encoder=class_encoder,\n",
    "#                        log_predictions=True,\n",
    "#                        max_rows=1000,\n",
    "#                        run=run,\n",
    "#                        commit=True)\n",
    "\n",
    "dataset = data['test']\n",
    "max_rows=100\n",
    "model = best_organism.model\n",
    "x, y_true = get_1_epoch_from_tf_data(dataset, max_rows=max_rows)\n",
    "y_true = y_true.numpy()\n",
    "\n",
    "y_prob, y_pred, losses = get_predictions(x, y_true, model)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "print(y_true.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(0, 38, size=1000)\n",
    "y_pred = np.random.randint(0, 38, size=1000)\n",
    "labels = np.arange(10)\n",
    "target_names = list(\"ABCDEFGHI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_classification_report(y_true, y_pred, target_names=None):\n",
    "    report = classification_report(y_true, y_pred, target_names=None, output_dict=True)\n",
    "\n",
    "    per_class_metrics = pd.DataFrame(report).T.iloc[:-3,:-1]\n",
    "    class_support = pd.DataFrame(report).T.iloc[:-3,-1:]\n",
    "    mean_metrics = pd.DataFrame(report).T.iloc[-3:,:-1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize=(15,20))\n",
    "    # sns.heatmap(pd.DataFrame(report).iloc[:-1,:].T, annot=True)\n",
    "    # sns.heatmap(pd.DataFrame(report).T, annot=True, ax=ax[0])\n",
    "#     cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    palette = sns.crayon_palette(list(sns.crayons.keys()))\n",
    "\n",
    "    sns.set_palette(palette)\n",
    "\n",
    "    sns.heatmap(mean_metrics, annot=True, ax=ax[0])#, cmap=\"Dark2\")\n",
    "    sns.heatmap(per_class_metrics, annot=True, ax=ax[1])#,cmap=cmap)#\"YlOrBr_r\")\n",
    "    sns.heatmap(class_support, annot=True, ax=ax[2])\n",
    "\n",
    "plot_classification_report(y_true, y_pred, target_names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"sex\", height=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_report = pd.DataFrame(report).T.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,9))\n",
    "sample_report.plot()#kind='bar', width=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=sample_report.iloc[:-3,:].T, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_pred':y_pred,\n",
    "             'y_true':y_true}).value_counts()\n",
    "\n",
    "sns.barplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='recall', data=sample_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "g = sns.JointGrid(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", space=0)\n",
    "\n",
    "\n",
    "\n",
    "g.plot_joint(sns.heatmap,data=df,x=\"body_mass_g\", y=\"bill_depth_mm\",\n",
    "             fill=True, clip=((2200, 6800), (10, 25)),\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "\n",
    "# g.plot_joint(sns.kdeplot,\n",
    "#              fill=True, clip=((2200, 6800), (10, 25)),\n",
    "#              thresh=0, levels=100, cmap=\"rocket\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# rs = np.random.RandomState(11)\n",
    "# x = rs.gamma(2, size=1000)\n",
    "# y = -.5 * x + rs.normal(size=1000)\n",
    "\n",
    "x = y_pred\n",
    "y = y_true\n",
    "\n",
    "\n",
    "sns.jointplot(x=x, y=y, kind=\"hex\", color=\"#4CB391\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.plot_joint(sns.heatmap,\n",
    "             fill=True, clip=((2200, 6800), (10, 25)),\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(6, 15))\n",
    "\n",
    "# Load the example car crash dataset\n",
    "crashes = sns.load_dataset(\"car_crashes\").sort_values(\"total\", ascending=False)\n",
    "\n",
    "# Plot the total crashes\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "            label=\"Total\", color=\"b\")\n",
    "\n",
    "# Plot the crashes where alcohol was involved\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=\"alcohol\", y=\"abbrev\", data=crashes,\n",
    "            label=\"Alcohol-involved\", color=\"b\")\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlim=(0, 24), ylabel=\"\",\n",
    "       xlabel=\"Automobile collisions per billion miles\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "# Load the brain networks example dataset\n",
    "df = sns.load_dataset(\"brain_networks\", header=[0, 1, 2], index_col=0)\n",
    "\n",
    "# Select a subset of the networks\n",
    "used_networks = [1, 5, 6, 7, 8, 12, 13, 17]\n",
    "used_columns = (df.columns.get_level_values(\"network\")\n",
    "                          .astype(int)\n",
    "                          .isin(used_networks))\n",
    "df = df.loc[:, used_columns]\n",
    "\n",
    "# Create a categorical palette to identify the networks\n",
    "network_pal = sns.husl_palette(8, s=.45)\n",
    "network_lut = dict(zip(map(str, used_networks), network_pal))\n",
    "\n",
    "# Convert the palette to vectors that will be drawn on the side of the matrix\n",
    "networks = df.columns.get_level_values(\"network\")\n",
    "network_colors = pd.Series(networks, index=df.columns).map(network_lut)\n",
    "\n",
    "# Draw the full plot\n",
    "g = sns.clustermap(df.corr(), center=0, cmap=\"vlag\",\n",
    "                   row_colors=network_colors, col_colors=network_colors,\n",
    "                   dendrogram_ratio=(.1, .2),\n",
    "                   cbar_pos=(.02, .32, .03, .2),\n",
    "                   linewidths=.75, figsize=(12, 13))\n",
    "\n",
    "g.ax_row_dendrogram.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=y_true, predict_vector=y_pred)\n",
    "\n",
    "\n",
    "fig, ax = plot_confusion_matrix(cm,normalize=True, title='Confusion matrix', annot=False, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from genetic_algorithm.plotting import *\n",
    "\n",
    "# model = best_organism.model\n",
    "# test_dataset = data['test']\n",
    "# max_rows=1000\n",
    "# k = 32\n",
    "# x, y_true = get_1_epoch_from_tf_data(test_dataset, max_rows=max_rows)\n",
    "# y_true = y_true.numpy()\n",
    "# y_prob, y_pred, losses = get_predictions(x, y_true, model)\n",
    "# highest_k_losses, hardest_k_examples, hardest_k_true_labels, hardest_k_predictions = get_hardest_k_examples(x, y_true, y_pred, losses, model, k=k)\n",
    "\n",
    "# %debug\n",
    "\n",
    "# %debug\n",
    "\n",
    "# dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from genetic_algorithm.chromosome import sampler\n",
    "# sampler(0)\n",
    "\n",
    "# phases = []\n",
    "# sampler=ChromosomeSampler()\n",
    "# phases.append(sampler(phase=0))\n",
    "# phases.append(sampler(phase=1))\n",
    "\n",
    "# child_chromosome = sampler(phase=0)#.generate_chromosome(phase=0)\n",
    "# child = Organism(chromosome=child_chromosome,\n",
    "#                  data=data,\n",
    "#                  config=config['data'],\n",
    "#                  phase=0,\n",
    "#                  generation_number=0,\n",
    "#                  organism_id=0,\n",
    "#                  best_organism=None)\n",
    "\n",
    "# (child._chromosome._state)\n",
    "\n",
    "# (child._chromosome.get_state())\n",
    "\n",
    "# # %%writefile main.py\n",
    "\n",
    "# # def main()\n",
    "# # print(config)\n",
    "# # best_organism = None\n",
    "# # for phase in range(config.generation.num_phases):\n",
    "# #     print(\"PHASE {}\".format(phase))\n",
    "# #     generation = Generation(data=data,\n",
    "# #                             generation_config=config['generation'],\n",
    "# #                             organism_config=config['organism'],\n",
    "# #                             phase=phase,\n",
    "# #                             previous_best_organism=best_organism,\n",
    "# #                             verbose=VERBOSE,\n",
    "# #                             DEBUG=DEBUG)\n",
    "    \n",
    "# #     best_organism = generation.run_phase()\n",
    "\n",
    "# (child_chromosome.get_chromosome(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================\n",
    "## TODO\n",
    "========\n",
    "\n",
    "\n",
    "\n",
    "* Implement saving\n",
    "* Log per-class plots for TP, TN, FP, FN, Recall, Precision\n",
    "* Fix test data loading for get_hardest_k_samples\n",
    "\n",
    "* Create dummy test model\n",
    "* Feed a ResNet backbone in as the previous best model\n",
    "* Follow that by feeding an arbitrary loaded model\n",
    "\n",
    "* Refactor according to keras idiomatic programmer style\n",
    "\n",
    "* Generate a DAG containing every model architecture, drawing connections between nodes indicating a type of step (e.g. mutation or crossover) to see the evolution of structure as a tree\n",
    "    * Consider passing run id down from each surviving organism to unify runs linking eachunique model\n",
    "    * Provide each organism a self._parent attribute pointing to identifying info about the parent.\n",
    "\n",
    "\n",
    "### Experiment Idea (12/1/20)\n",
    "* Optimize each generation by maximizing validation recall, rather than validation accuracy\n",
    "\n",
    "### Experiment 2\n",
    "* Add initalizers HeNormal and HeUniform to chromosome\n",
    "[HeNormal] (https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal)\n",
    "\n",
    "### Experiment 3\n",
    "- Label smoothing\n",
    "\n",
    "\n",
    "### Experiment 4 (Added 2 AM 12/2/20)\n",
    "- Integrate multi-dataset transfer learning workflow\n",
    "\n",
    "1. Alternate phase_0 -> dataset_0, phase_1 -> dataset_1\n",
    "    Then, either\n",
    "    a. phase_2 -> back to phase_0\n",
    "    or\n",
    "    b. phase_2 -> Interleave samples from dataset_0 and dataset_1\n",
    "\n",
    "### Experiment 5 (Added 5:15 AM 12/2/20)\n",
    "\n",
    "#### Signal vs Noise Scenario for metalearning/hparam search\n",
    "Based on: https://wandb.ai/stacey/pytorch_intro/reports/Meaning-and-Noise-in-Hyperparameter-Search--Vmlldzo0Mzk5MQ\n",
    "Perform 2 versions of an Experiment:\n",
    "Question: \"How do we know when the observed effect sizes from our model-tuning efforts are meaningful?\"\n",
    "Step 1. Perform k-identical trials with everything but the random seed fixed.\n",
    "\n",
    "Step 2. For another k trials, fix the random seed but perform hparam search/metalearning algorithm for each trial\n",
    "\n",
    "Hypothesis: The relative discrepancy in performance between version 1 (noise) and version 2 (signal) should reflect only the signal and no noise\n",
    "\n",
    "Future Work: \"A promising next direction would be to quantify the number of runs/samples needed to ensure statistically significant results relative to a noise baseline.\"\n",
    "\n",
    "============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left off Running Notebook (7 AM 12/1/20):\n",
    "- Running full plant_village 3 phase, 3 generation, 5 organism-per-population search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Using tfds.features.ClassLabel\n",
    "\n",
    "# feature_labels = tfds.features.ClassLabel(names=vocab)\n",
    "# data = ['Potato___healthy',\n",
    "#         'Potato___Late_blight',\n",
    "#         'Raspberry___healthy',\n",
    "#         'Soybean___healthy',\n",
    "#         'Squash___Powdery_mildew',\n",
    "#         'Strawberry___healthy',\n",
    "#         'Strawberry___Leaf_scorch',\n",
    "#         'Tomato___Bacterial_spot',\n",
    "#         'Tomato___Early_blight',\n",
    "#         'Tomato___healthy']\n",
    "\n",
    "# data += data[::-1]\n",
    "# print([feature_labels.str2int(label) for label in data])\n",
    "# data = train_data\n",
    "# data_enc = data.map(lambda x,y: (x, feature_labels.int2str(y)))\n",
    "\n",
    "### 2. Using StringLookup and CategoryEncoding Layers\n",
    "\n",
    "# layer = StringLookup(vocabulary=vocab, num_oov_indices=0, mask_token=None)\n",
    "# i_layer = StringLookup(vocabulary=layer.get_vocabulary(), invert=True)\n",
    "# int_data = layer(data)\n",
    "\n",
    "# print(len(layer.get_vocabulary()))\n",
    "# print(len(class_encoder.class_list))\n",
    "# print(set(layer.get_vocabulary())==set(class_encoder.class_list))\n",
    "\n",
    "# i_layer = StringLookup(vocabulary=layer.get_vocabulary(), invert=True)\n",
    "# int_data = layer(data)\n",
    "\n",
    "# print(layer(data))\n",
    "# print(i_layer(int_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from tensorflow.keras.layers.experimental.preprocessing import StringLookup, CategoryEncoding\n",
    "# # data = tf.constant([\"a\", \"b\", \"c\", \"b\", \"c\", \"a\"])\n",
    "# # # Use StringLookup to build an index of the feature values\n",
    "# # indexer = StringLookup()\n",
    "# # indexer.adapt(data)\n",
    "# # # Use CategoryEncoding to encode the integer indices to a one-hot vector\n",
    "# # encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "# # encoder.adapt(indexer(data))\n",
    "# # # Convert new test data (which includes unknown feature values)\n",
    "# # test_data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"e\", \"\"])\n",
    "# # encoded_data = encoder(indexer(test_data))\n",
    "# # print(encoded_data)\n",
    "\n",
    "# vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
    "# data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
    "# layer = StringLookup(vocabulary=vocab)\n",
    "# i_layer = StringLookup(vocabulary=layer.get_vocabulary(), invert=True)\n",
    "# int_data = layer(data)\n",
    "\n",
    "# print(layer(data))\n",
    "# print(i_layer(int_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZRopbXcoeJ6"
   },
   "outputs": [],
   "source": [
    "# VERBOSE = True\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# from box import Box\n",
    "# from bunch import Bunch\n",
    "# # from pprint import pprint as pp\n",
    "# import random\n",
    "\n",
    "# ActivationLayers = Box(ReLU=ReLU, ELU=ELU, LeakyReLU=LeakyReLU)\n",
    "# PoolingLayers = Box(MaxPool2D=MaxPool2D, AveragePooling2D=AveragePooling2D)\n",
    "\n",
    "# class Chromosome(stateful.Stateful):#BaseChromosome):#(NamedTuple):\n",
    "    \n",
    "#     def __init__(self,\n",
    "#                  hparams: Dict=None,\n",
    "#                  name=''):\n",
    "#         super().__init__()\n",
    "#         self.set_state(hparams)\n",
    "\n",
    "#     def get_state(self):\n",
    "#         \"\"\"Returns the current state of this object.\n",
    "#         This method is called during `save`.\n",
    "#         \"\"\"\n",
    "#         return self._state\n",
    "        \n",
    "\n",
    "#     def set_state(self, state):\n",
    "#         \"\"\"Sets the current state of this object.\n",
    "#         This method is called during `reload`.\n",
    "#         # Arguments:\n",
    "#           state: Dict. The state to restore for this object.\n",
    "#         \"\"\"\n",
    "#         self._state = state\n",
    "        \n",
    "#     @property\n",
    "#     def deserialized_state(self):\n",
    "#         state = copy.deepcopy(self.get_state())\n",
    "#         state['activation_type'] = ActivationLayers[state['activation_type']]\n",
    "#         state['pool_type'] = PoolingLayers[state['pool_type']]\n",
    "\n",
    "# #         state['activation_type'] = [ActivationLayers[act_layer] for act_layer in state['activation_type']]\n",
    "# #         state['pool_type'] = [PoolingLayers[pool_layer] for pool_layer in state['pool_type']]\n",
    "#         return state\n",
    "\n",
    "\n",
    "# import copy\n",
    "\n",
    "# class ChromosomeOptions(stateful.Stateful): #BaseOptions): #object):\n",
    "#     \"\"\"\n",
    "#     Container class for encapsulating variable-length lists of potential gene variants (individual hyperparameters).\n",
    "#     To be used as a reservoir from which to sample a complete chromosome made up of 1 variant per gene.\n",
    "    \n",
    "#     This should be logged for describing the scope of a given AutoML experiment's hyperparameter search space\n",
    "\n",
    "#     Gene: The unique identifier of a particular hyperparameter that may reference any of a set of possible variant values.\n",
    "#     Variant: The particular value of a gene. Used to refer to the 1 value for a single chromosome instance, or 1 value from a set of gene options.\n",
    "\n",
    "#     Args:\n",
    "#         NamedTuple ([type]): [description]\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  hparam_lists,\n",
    "#                  phase=0,\n",
    "#                  seed=None):\n",
    "        \n",
    "# #         self.__chromosomes = {k:v for k,v in locals().items() if k not in ['self', 'kwargs'] and not k.startswith('__')}\n",
    "# #         print(self.__chromosomes)\n",
    "        \n",
    "#         self.set_state(hparam_lists, phase=phase, seed=seed)\n",
    "\n",
    "#     def get_state(self):\n",
    "#         \"\"\"Returns the current state of this object.\n",
    "#         This method is called during `save`.\n",
    "#         \"\"\"\n",
    "#         return self.state\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         config = copy.deepcopy(self.state)\n",
    "#         return config\n",
    "        \n",
    "\n",
    "#     def set_state(self, state, phase=0, seed=None):\n",
    "#         \"\"\"Sets the current state of this object.\n",
    "#         This method is called during `reload`.\n",
    "#         # Arguments:\n",
    "#           state: Dict. The state to restore for this object.\n",
    "#         \"\"\"\n",
    "#         self.set_seed(seed)\n",
    "#         self.phase = phase\n",
    "#         self.state = state\n",
    "\n",
    "#     def set_seed(self, seed=None):\n",
    "#         self.seed = seed\n",
    "#         self.rng = np.random.default_rng(seed)\n",
    "        \n",
    "#     def sample_k_variants_from_gene(self, gene: str, k: int=1):\n",
    "#         '''\n",
    "#         Randomly sample the list of variants corresponding to the key indicated by the first arg, 'gene'. Produce a random sequence of length k, with the default==1.\n",
    "        \n",
    "#         Note: If k==1: this automatically returns a single unit from the variants list, which may or may not be a scalar object (e.g. int, str, float)\n",
    "#         If k > 1: then the sampled variants will always be returned in a list.\n",
    "        \n",
    "#         '''\n",
    "#         all_variants = self.chromosomes[gene]\n",
    "#         variant_idx = self.rng.integers(low=0, high=len(all_variants), size=k)\n",
    "#         sampled_variants = [all_variants[idx] for idx in variant_idx.tolist()]\n",
    "#         if k==1:\n",
    "#             sampled_variants = sampled_variants[0]\n",
    "#         return sampled_variants\n",
    "    \n",
    "#     def generate_chromosome(self, phase: int=None, seed=None):\n",
    "#         '''\n",
    "#         Primary function for utilizing a ChromosomeOptions object during experimentation.\n",
    "#         Running this function will randomly generate a new Chromosome instance for which each genetic variant is randomly sampled from this object's contained data,\n",
    "#         in the form of mappings between gene names as keys, and lists of variants as values.\n",
    "#         '''\n",
    "#         return Chromosome(hparams={gene:self.sample_k_variants_from_gene(gene) for gene in self.chromosomes.keys()})\n",
    "    \n",
    "#     def generate_k_chromosomes(self, k: int=1, seed=None):\n",
    "#         return [self.generate_chromosome(seed=seed) for _ in range(k)]\n",
    "        \n",
    "#     @property\n",
    "#     def chromosomes(self):\n",
    "#         return self.state\n",
    "\n",
    "    \n",
    "#     @property\n",
    "#     def deserialized_state(self):\n",
    "#         state = copy.deepcopy(self.state)\n",
    "#         state['activation_type'] = [ActivationLayers[act_layer] for act_layer in state['activation_type']]\n",
    "#         state['pool_type'] = [PoolingLayers[pool_layer] for pool_layer in state['pool_type']]\n",
    "#         return state\n",
    "    \n",
    "\n",
    "# class ChromosomeSampler:\n",
    "    \n",
    "#     def __call__(self, phase: int):\n",
    "        \n",
    "#         if phase==0:\n",
    "#             options = ChromosomeOptions({\n",
    "# #                                       'b_include_layer':[True],\n",
    "#                                       'a_filter_size':[(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "#                                       'a_include_BN':[True, False],\n",
    "#                                       'a_output_channels':[8, 16, 32, 64, 128, 256, 512],\n",
    "#                                       'activation_type':['ReLU', 'ELU', 'LeakyReLU'],\n",
    "#                                       'b_filter_size':[(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "#                                       'b_include_BN':[True, False],\n",
    "#                                       'b_output_channels':[8, 16, 32, 64, 128, 256, 512],\n",
    "#                                       'include_pool':[True, False],\n",
    "#                                       'pool_type':['MaxPool2D', 'AveragePooling2D'],\n",
    "#                                       'include_skip':[True, False]\n",
    "#                                       },\n",
    "#                                       phase=phase)\n",
    "\n",
    "#         else:\n",
    "#             options = ChromosomeOptions({\n",
    "#                                       'b_include_layer':[True, False],\n",
    "#                                       'a_filter_size':[(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "#                                       'a_include_BN':[True, False],\n",
    "#                                       'a_output_channels':[8, 16, 32, 64, 128, 256, 512],\n",
    "#                                       'activation_type':['ReLU', 'ELU', 'LeakyReLU'],\n",
    "#                                       'b_filter_size':[(1,1), (3,3), (5,5), (7,7), (9,9)],\n",
    "#                                       'b_include_BN':[True, False],\n",
    "#                                       'b_output_channels':[8, 16, 32, 64, 128, 256, 512],\n",
    "#                                       'include_pool':[True, False],\n",
    "#                                       'pool_type':['MaxPool2D', 'AveragePooling2D'],\n",
    "#                                       'include_skip':[True, False]\n",
    "#                                       },\n",
    "#                                       phase=phase)\n",
    "#         return options.generate_chromosome(phase=phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "\n",
    "# class Organism:\n",
    "#     def __init__(self,\n",
    "#                  data: Dict[str,tf.data.Dataset],\n",
    "#                  config=None,\n",
    "#                  chromosome=None,\n",
    "#                  phase=0,\n",
    "#                  generation_number=0,\n",
    "#                  organism_id=0,\n",
    "#                  best_organism=None):\n",
    "#         '''\n",
    "        \n",
    "#         Organism is an actor with a State that can take Action in the environment\n",
    "        \n",
    "#         config is a . accessible dict object containing model params that will stay constant during evolution\n",
    "#         chromosome is a dictionary of genes\n",
    "#         phase is the phase that the individual belongs to\n",
    "#         best_organism is the best organism of the previous phase\n",
    "        \n",
    "#         TODO:\n",
    "        \n",
    "#         1. implement to_json and from_json methods for copies\n",
    "#         2. Separate out step where organism is associated with a dataset\n",
    "#         '''\n",
    "#         self.data = data\n",
    "#         self.train_data = data['train']\n",
    "#         self.val_data = data['val']\n",
    "#         self.test_data = data['test']\n",
    "#         self.config = config\n",
    "#         self.chromosome = chromosome\n",
    "#         self.phase = phase\n",
    "#         self.generation_number = generation_number\n",
    "#         self.organism_id = organism_id\n",
    "#         self.best_organism=best_organism\n",
    "\n",
    "#         if phase > 0:\n",
    "#             if best_organism is None:\n",
    "#                 print(f'phase {phase} gen {generation} organism {organism_id}.\\nNo previous best model, creating from scratch.')\n",
    "#             else:\n",
    "#                 self.last_model = best_organism.model\n",
    "            \n",
    "#         self.debug = DEBUG\n",
    "    \n",
    "#     @property\n",
    "#     def name(self):\n",
    "#         return f'phase_{self.phase}-gen_{self.generation_number}-organism_{self.organism_id}'\n",
    "    \n",
    "#     @property\n",
    "#     def config(self):\n",
    "#         return self._config\n",
    "    \n",
    "#     @config.setter\n",
    "#     def config(self, config=None):\n",
    "#         config = config or OmegaConf.create({})\n",
    "#         print(config)\n",
    "#         config.input_shape = config.input_shape or (224,224,3)\n",
    "#         config.output_size = config.output_size or 38\n",
    "#         config.epochs_per_organism = config.epochs_per_organism or 5\n",
    "#         self._config = config\n",
    "        \n",
    "#     def get_metrics(self):\n",
    "#         return [tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.TruePositives(name='tp'),\n",
    "#                 tf.keras.metrics.FalsePositives(name='fp'),\n",
    "#                 tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "#                 tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall'),\n",
    "#                 tf.keras.metrics.AUC(name='auc')]\n",
    "    \n",
    "#     @property\n",
    "#     def fitness_metric_name(self):\n",
    "#         return 'accuracy'\n",
    "   \n",
    "#     @property\n",
    "#     def chromosome(self):\n",
    "#         return self._chromosome.deserialized_state\n",
    "    \n",
    "#     @chromosome.setter\n",
    "#     def chromosome(self, chromosome):\n",
    "#         self._chromosome = chromosome\n",
    "        \n",
    "    \n",
    "#     def build_model(self):\n",
    "#         '''\n",
    "#         This is the function to build the keras model\n",
    "#         '''\n",
    "#         K.clear_session()\n",
    "#         gc.collect()\n",
    "#         inputs = Input(shape=self.config.input_shape)\n",
    "#         if self.phase != 0:\n",
    "#             # Slice the prev best model # Use the model as a layer # Attach new layer to the sliced model\n",
    "#             intermediate_model = Model(inputs=self.last_model.input,\n",
    "#                                        outputs=self.last_model.layers[-3].output)\n",
    "#             for layer in intermediate_model.layers:\n",
    "#                 # To make the iteration efficient\n",
    "#                 layer.trainable = False\n",
    "#             inter_inputs = intermediate_model(inputs)\n",
    "#             x = Conv2D(filters=self.chromosome['a_output_channels'],\n",
    "#                        padding='same',\n",
    "#                        kernel_size=self.chromosome['a_filter_size'],\n",
    "#                        use_bias=self.chromosome['a_include_BN'])(inter_inputs)\n",
    "#             # This is to ensure that we do not randomly chose anothere activation\n",
    "#             self.chromosome['activation_type'] = self.best_organism.chromosome['activation_type']\n",
    "#         else:\n",
    "#             # For PHASE 0 only\n",
    "#             # input layer\n",
    "#             x = Conv2D(filters=self.chromosome['a_output_channels'],\n",
    "#                        padding='same',\n",
    "#                        kernel_size=self.chromosome['a_filter_size'],\n",
    "#                        use_bias=self.chromosome['a_include_BN'])(inputs)\n",
    "            \n",
    "#         if self.chromosome['a_include_BN']:\n",
    "#             x = BatchNormalization()(x)\n",
    "#         x = self.chromosome['activation_type']()(x)\n",
    "#         if self.chromosome['include_pool']:\n",
    "#             x = self.chromosome['pool_type'](strides=(1,1),\n",
    "#                                              padding='same')(x)\n",
    "#         if self.phase != 0 and self.chromosome['b_include_layer'] == False:\n",
    "#             # Except for PHASE0, there is a choice for\n",
    "#             # the number of layers that the model wants\n",
    "#             if self.chromosome['include_skip']:\n",
    "#                 y = Conv2D(filters=self.chromosome['a_output_channels'],\n",
    "#                            kernel_size=(1,1),\n",
    "#                            padding='same')(inter_inputs)\n",
    "#                 x = Add()([y,x])\n",
    "#             x = GlobalAveragePooling2D()(x)\n",
    "#             x = Dense(self.config.output_size, activation='softmax')(x)\n",
    "#         else:\n",
    "#             # PHASE0 or no skip\n",
    "#             # in the tail\n",
    "#             x = Conv2D(filters=self.chromosome['b_output_channels'],\n",
    "#                        padding='same',\n",
    "#                        kernel_size=self.chromosome['b_filter_size'],\n",
    "#                        use_bias=self.chromosome['b_include_BN'])(x)\n",
    "#             if self.chromosome['b_include_BN']:\n",
    "#                 x = BatchNormalization()(x)\n",
    "#             x = self.chromosome['activation_type']()(x)\n",
    "#             if self.chromosome['include_skip']:\n",
    "#                 y = Conv2D(filters=self.chromosome['b_output_channels'],\n",
    "#                            padding='same',\n",
    "#                            kernel_size=(1,1))(inputs)\n",
    "#                 x = Add()([y,x])\n",
    "#             x = GlobalAveragePooling2D()(x)\n",
    "#             x = Dense(self.config.output_size, activation='softmax')(x)\n",
    "#         self.model = Model(inputs=[inputs], outputs=[x])\n",
    "#         self.model.compile(optimizer='adam',\n",
    "#                            loss='categorical_crossentropy',\n",
    "#                            metrics=self.get_metrics())\n",
    "        \n",
    "#     def fitnessFunction(self,\n",
    "#                         train_data,\n",
    "#                         val_data,\n",
    "#                         generation_number):\n",
    "#         '''\n",
    "#         This function is used to calculate the\n",
    "#         fitness of an individual.\n",
    "#         '''\n",
    "#         print('FFITNESS FUNCTION FFS')\n",
    "#         print('vars():', vars())\n",
    "#         self.run = wandb.init(**self.get_wandb_credentials(phase=self.phase,\n",
    "#                                                 generation_number=generation_number),\n",
    "#                    config=self.config)\n",
    "        \n",
    "#         self.model.fit(train_data,\n",
    "#                        steps_per_epoch=self.config.steps_per_epoch,\n",
    "#                        epochs=self.config.epochs_per_organism,\n",
    "#                        callbacks=[WandbCallback()],\n",
    "#                        verbose=1)\n",
    "#         self.results = self.model.evaluate(val_data,\n",
    "#                                            steps=self.config.validation_steps,\n",
    "#                                            return_dict=True,\n",
    "#                                            verbose=1)\n",
    "#         self.fitness = self.results[self.fitness_metric_name]\n",
    "#         print(self.name)\n",
    "#         print('fitness:', self.fitness)\n",
    "#         print('results:\\n', len(self.results))\n",
    "#         print(self.results)\n",
    "        \n",
    "        \n",
    "# #     @results.setter\n",
    "# #     def results(self, metrics_values):\n",
    "# #         self._results = {name:values for name, value in zip(self.model.metrics_names, metrics_values)}\n",
    "        \n",
    "# #     @property\n",
    "# #     def results(self):\n",
    "# #         return self._results\n",
    "        \n",
    "#     def crossover(self,\n",
    "#                   partner,\n",
    "#                   generation_number):\n",
    "#         '''\n",
    "#         This function helps in making children from two\n",
    "#         parent individuals.\n",
    "#         '''\n",
    "#         child_chromosome = {}\n",
    "#         endpoint = np.random.randint(low=0, high=len(self.chromosome))\n",
    "#         for idx, key in enumerate(self.chromosome):\n",
    "#             if idx <= endpoint:\n",
    "#                 child_chromosome[key] = self.chromosome[key]\n",
    "#             else:\n",
    "#                 child_chromosome[key] = partner.chromosome[key]\n",
    "#         child = Organism(chromosome=child_chromosome,\n",
    "#                          data=self.data,\n",
    "#                          config=self.config,\n",
    "#                          phase=self.phase,\n",
    "#                          generation_number=generation_number,\n",
    "#                          organism_id=f'{self.organism_id}+{partner.organism_id}',\n",
    "#                          best_organism=self.best_organism)\n",
    "        \n",
    "#         child.build_model()\n",
    "#         child.fitnessFunction(self.train_data,\n",
    "#                               self.val_data,\n",
    "#                               generation_number=generation_number)\n",
    "#         return child\n",
    "    \n",
    "#     def mutation(self, generation_number):\n",
    "#         '''\n",
    "#         One of the gene is to be mutated.\n",
    "#         '''\n",
    "#         index = np.random.randint(0, len(self.chromosome))\n",
    "#         key = list(self.chromosome.keys())[index]\n",
    "#         if  self.phase != 0:\n",
    "#             self.chromosome[key] = options[key][np.random.randint(len(options[key]))]\n",
    "#         else:\n",
    "#             self.chromosome[key] = options_phase0[key][np.random.randint(len(options_phase0[key]))]\n",
    "#         self.build_model()\n",
    "#         self.fitnessFunction(self.train_data,\n",
    "#                              self.val_data,\n",
    "#                              generation_number=generation_number)\n",
    "    \n",
    "#     def show(self):\n",
    "#         '''\n",
    "#         Util function to show the individual's properties.\n",
    "#         '''\n",
    "#         pp.pprint(self.config)\n",
    "#         pp.pprint(self.chromosome)\n",
    "        \n",
    "        \n",
    "#     def get_wandb_credentials(self, phase: int=None, generation_number: int=None):\n",
    "#         phase = phase or self.phase\n",
    "#         generation_number = generation_number or self.generation_number\n",
    "#         if self.debug:\n",
    "#             return get_wandb_credentials(phase=phase,\n",
    "#                                           generation_number=generation_number,\n",
    "#                                           entity=\"jrose\",\n",
    "#                                           project=f\"vlga-plant_village-DEBUG\")           \n",
    "#         return get_wandb_credentials(phase=phase,\n",
    "#                                       generation_number=generation_number,\n",
    "#                                       entity=\"jrose\",\n",
    "#                                       project=f\"vlga-plant_village\")\n",
    "\n",
    "        \n",
    "    \n",
    "# def get_wandb_credentials(phase: int,\n",
    "#                           generation_number: int,\n",
    "#                           entity=\"jrose\",\n",
    "#                           project=f\"vlga-plant_village\"):\n",
    "    \n",
    "#     return dict(entity=entity,\n",
    "#                 project=project,\n",
    "#                 group='KAGp{}'.format(phase),\n",
    "#                 job_type='g{}'.format(generation_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema for defining, loading, using, and logging configuration for hparam search\n",
    "\n",
    "\n",
    "### 1. Begin Hooks\n",
    "\n",
    "    a. at_search_begin\n",
    "        Store hparam search space definitions in a file called `search_space.json`\n",
    "    b. at_trial_begin\n",
    "\n",
    "    c. at_train_begin\n",
    "\n",
    "    d. at_epoch_begin\n",
    "\n",
    "    e. at_batch_begin\n",
    "\n",
    "### 2. End Hooks\n",
    "\n",
    "    a. at_batch_end\n",
    "    \n",
    "    b. at_epoch_end\n",
    "\n",
    "    c. at_train_end\n",
    "\n",
    "    d. at_trial_end\n",
    "\n",
    "    e. at_search_end\n",
    "\n",
    "\n",
    "7. \n",
    "\n",
    "## 1. INTERESTING REFACTOR IDEA:\n",
    "    TODO: Refactor chromosome structure to standardize the configuration options for repeated model structures\n",
    "    ### (3 AM 11/27/20)\n",
    "\n",
    "    e.g. Create a separate ConvOptions(NamedTuple) class to contain all 3 options:\n",
    "        filter_size\n",
    "    include_BN\n",
    "    output_channels\n",
    "\n",
    "    Then in each \"ChromosomeOptions\" (consider making each of those a chromosome, and upgrading what's now a chromosome to a full Genome)\n",
    "    store a separate ConvOptions for layer a and layer b, separately.\n",
    "\n",
    "\n",
    "## 2. TODO: \n",
    "    Consider transferring mutate() method from Organism to Chromosome, while potentially keeping crossover() method as part of organism's namespace. Purpose is to encapsulate functionality as close as possible with the data/abstractions it will operate on\n",
    "\n",
    "\n",
    "## 3. To Consider:\n",
    "    How can I quantify the information coverage and computational complexity of a given set of chromosome options? \n",
    "\n",
    "        a. Start with the raw # of permutations of all chromosome options\n",
    "        b. Adjust by the expected coverage for each variant. E.g. How much of the hyperparameter space are we covering in our naive uniform grid search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1602853528916,
     "user": {
      "displayName": "Aritra Roy Gosthipaty",
      "photoUrl": "",
      "userId": "14289131178028582626"
     },
     "user_tz": -330
    },
    "id": "cfa1Y5TNVYcY"
   },
   "outputs": [],
   "source": [
    "# def softmax(x):\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "\n",
    "# class Generation:\n",
    "#     def __init__(self,\n",
    "#                  data,\n",
    "#                  generation_config,\n",
    "#                  organism_config,\n",
    "#                  phase,\n",
    "#                  previous_best_organism,\n",
    "#                  verbose: bool=False):\n",
    "#         self.data = data\n",
    "#         self.config = generation_config\n",
    "#         self.organism_config = organism_config\n",
    "#         self.population = []\n",
    "#         self.generation_number = 0\n",
    "#         self.phase = phase\n",
    "#         # creating the first population: GENERATION_0\n",
    "#         # can be thought of as the setup function\n",
    "#         self.previous_best_organism = previous_best_organism or None\n",
    "#         self.best = {}\n",
    "#         self._initialized = False\n",
    "#         self.initialize_population(verbose=verbose)\n",
    "#         self.verbose = verbose\n",
    "        \n",
    "#     @property\n",
    "#     def config(self):\n",
    "#         return self._config\n",
    "    \n",
    "#     @config.setter\n",
    "#     def config(self, config=None):\n",
    "#         config = config or OmegaConf.create({})\n",
    "#         config.population_size = config.population_size or 5\n",
    "#         config.num_generations_per_phase = config.num_generations_per_phase or 3\n",
    "#         config.fitSurvivalRate = config.fitSurvivalRate or 0.5\n",
    "#         config.unfitSurvivalProb = config.unfitSurvivalProb or 0.2\n",
    "#         config.mutationRate = config.mutationRate or 0.1\n",
    "#         config.num_phases = config.num_phases or 5\n",
    "        \n",
    "#         self._config = config\n",
    "#         self.__dict__.update(config)\n",
    "        \n",
    "        \n",
    "#     def initialize_population(self, verbose=True):\n",
    "#         '''\n",
    "#         1. Create self.population_size individual organisms from scratch by randomly sampling an initial set of hyperparameters (a chromosome)\n",
    "#         2. As each is instantiated, build its model\n",
    "#         3. Assess their fitness one-by-one\n",
    "#         4. Sort models by relative fitness so we have a (potentially) new Best Organism (best model)\n",
    "#         4. Increment generation number to 1\n",
    "#         '''\n",
    "\n",
    "#         for idx in range(self.population_size):\n",
    "#             if verbose:\n",
    "#                 print('<'*10,' '*5,'>'*10)\n",
    "#                 print(f'Creating, training then testing organism {idx} out of a maximum {self.population_size} from generation {self.generation_number} and phase {self.phase}')\n",
    "#             org = Organism(chromosome=sampler(self.phase), #.get_state(),\n",
    "#                            data=self.data,\n",
    "#                            config=self.organism_config,\n",
    "#                            phase=self.phase,\n",
    "#                            generation_number=self.generation_number,\n",
    "#                            organism_id=idx,\n",
    "#                            best_organism=self.previous_best_organism)\n",
    "#             org.build_model()\n",
    "#             org.fitnessFunction(org.data['train'],\n",
    "#                                 org.data['test'],\n",
    "#                                 generation_number=self.generation_number)\n",
    "#             self.population.append(org)\n",
    "\n",
    "#         self._initialized = True\n",
    "#         self.sortModel(verbose=verbose)\n",
    "#         self.generation_number += 1\n",
    "#         self.evaluate(run=self.population[0].run)\n",
    "\n",
    "#     def sortModel(self, verbose: bool=True):\n",
    "#         '''\n",
    "#         sort the models according to the \n",
    "#         fitness in descending order.\n",
    "#         '''\n",
    "#         previous_best = self.best_fitness\n",
    "#         fitness = [ind.fitness for ind in self.population]\n",
    "#         sort_index = np.argsort(fitness)[::-1]\n",
    "#         self.population = [self.population[index] for index in sort_index]\n",
    "\n",
    "#         if self.best_organism_so_far.fitness > previous_best:\n",
    "#             self.best['organism'] = self.best_organism_so_far\n",
    "#             self.best['model'] = self.best_organism_so_far.model\n",
    "#             self.best['fitness'] = self.best_organism_so_far.fitness\n",
    "            \n",
    "#             if verbose:\n",
    "#                 print(f'''NEW BEST MODEL:\n",
    "#                 Fitness = {self.best[\"fitness\"]:.3f}\n",
    "#                 Previous Fitness = {previous_best:.3f}\n",
    "#                 Name = {self.best['organism'].name}\n",
    "#                 chromosome = {self.best['organism'].chromosome}''')\n",
    "        \n",
    "#     @property\n",
    "#     def best_organism_so_far(self):\n",
    "#         if self._initialized:\n",
    "#             return self.population[0]\n",
    "#         else:\n",
    "#             return self.previous_best_organism\n",
    "\n",
    "#     @property\n",
    "#     def best_fitness(self):\n",
    "#         if self._initialized:\n",
    "#             return self.population[0].fitness\n",
    "#         elif self.previous_best_organism is not None:\n",
    "#             return self.previous_best_organism.fitness\n",
    "#         else:\n",
    "#             return 0.0\n",
    "        \n",
    "        \n",
    "#     def generate(self):\n",
    "#         '''\n",
    "#         Generate a new generation in the same phase\n",
    "#         '''\n",
    "#         number_of_fit = int(self.population_size * self.fitSurvivalRate)\n",
    "#         new_pop = self.population[:number_of_fit]\n",
    "#         for individual in self.population[number_of_fit:]:\n",
    "#             if np.random.rand() <= self.unfitSurvivalProb:\n",
    "#                 new_pop.append(individual)\n",
    "#         for index, individual in enumerate(new_pop):\n",
    "#             if np.random.rand() <= self.mutationRate:\n",
    "#                 new_pop[index].mutation(generation_number=self.generation_number)\n",
    "#         fitness = [ind.fitness for ind in new_pop]\n",
    "#         children=[]\n",
    "#         for idx in range(self.population_size-len(new_pop)):\n",
    "#             parents = np.random.choice(new_pop, replace=False, size=(2,), p=softmax(fitness))\n",
    "#             A=parents[0]\n",
    "#             B=parents[1]\n",
    "#             child=A.crossover(B, generation_number=self.generation_number)\n",
    "#             children.append(child)\n",
    "#         self.population = new_pop+children\n",
    "#         self.sortModel()\n",
    "#         self.generation_number+=1\n",
    "\n",
    "#     def evaluate(self, run=None, last=False):\n",
    "#         '''\n",
    "#         Evaluate the generation\n",
    "#         '''\n",
    "#         print('EVALUATE')\n",
    "#         fitness = [ind.fitness for ind in self.population]\n",
    "\n",
    "#         BestOrganism = self.population[0]\n",
    "#         if run is None:\n",
    "#             run = BestOrganism.run\n",
    "#         run.log({'population_size':len(fitness)}, commit=False)\n",
    "#         run.log({'Best fitness': fitness[0]}, commit=False)\n",
    "#         run.log({'Average fitness': sum(fitness)/len(fitness)})\n",
    "        \n",
    "#         self.population[0].show()\n",
    "#         print('BEST ORGANISM', BestOrganism.name)\n",
    "#         k=16\n",
    "#         if last:\n",
    "#             k=32\n",
    "#         model_path = f'best-model-phase_{self.phase}.png'\n",
    "#         tf.keras.utils.plot_model(BestOrganism.model, to_file=model_path)\n",
    "#         run.log({\"best_model\": [wandb.Image(model_path, caption=f\"Best Model phase_{self.phase}\")]})\n",
    "#         log_high_loss_examples(BestOrganism.test_data,\n",
    "#                                BestOrganism.model, \n",
    "#                                k=k,\n",
    "#                                run=run)\n",
    "            \n",
    "#         return BestOrganism\n",
    "\n",
    "#     def run_generation(self):\n",
    "#         print('RUN GENERATION')\n",
    "#         self.generate()\n",
    "#         last = False\n",
    "#         if self.generation_number == self.num_generations_per_phase:\n",
    "#             last = True\n",
    "#         best_organism = self.evaluate(last=last)\n",
    "#         return best_organism\n",
    "        \n",
    "#     def run_phase(self):#, num_generations_per_phase: int=1):\n",
    "#         print('RUN PHASE')\n",
    "#         while self.generation_number < self.num_generations_per_phase:\n",
    "#             best_organism = self.run_generation()\n",
    "#             print(f'FINISHED GENERATION {self.generation_number}')\n",
    "#             print(vars())\n",
    "            \n",
    "#             if self.verbose:\n",
    "#                 print(f'FINISHED generation {self.generation_number}. Best fitness = {best_organism.fitness}')\n",
    "            \n",
    "#         return self.population[0] #best_organism\n",
    "        \n",
    "#             return self.population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
